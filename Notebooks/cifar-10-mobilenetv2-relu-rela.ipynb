{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.8"
    },
    "colab": {
      "name": "cifar-10-mobilenetv2-mish.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ymlgithub/Mish/blob/master/Notebooks/cifar-10-mobilenetv2-relu-rela.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WkBzKWtOTQHE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "06420bd0-c3a4-4711-c9d9-749d66b7d03e"
      },
      "source": [
        "!mkdir ../input"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "mkdir: cannot create directory ‘../input’: File exists\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "id": "R-bqJnXUSkq4",
        "colab_type": "code",
        "outputId": "f5b3233e-78b6-4ab3-d18e-570172a34066",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "\n",
        "import os\n",
        "print(os.listdir(\"../input\"))\n",
        "\n",
        "import time\n",
        "\n",
        "# import pytorch\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.optim import SGD,Adam,lr_scheduler\n",
        "from torch.utils.data import random_split\n",
        "import torchvision\n",
        "from torchvision import transforms, datasets\n",
        "from torch.utils.data import DataLoader"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9xJkA7fKSkq9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# define transformations for train\n",
        "train_transform = transforms.Compose([\n",
        "    transforms.RandomHorizontalFlip(p=.40),\n",
        "    transforms.RandomRotation(30),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize([0.5, 0.5, 0.5], [0.5, 0.5, 0.5])])\n",
        "\n",
        "# define transformations for test\n",
        "test_transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize([0.5, 0.5, 0.5], [0.5, 0.5, 0.5])])\n",
        "\n",
        "# define training dataloader\n",
        "def get_training_dataloader(train_transform, batch_size=128, num_workers=0, shuffle=True):\n",
        "    \"\"\" return training dataloader\n",
        "    Args:\n",
        "        train_transform: transfroms for train dataset\n",
        "        path: path to cifar100 training python dataset\n",
        "        batch_size: dataloader batchsize\n",
        "        num_workers: dataloader num_works\n",
        "        shuffle: whether to shuffle \n",
        "    Returns: train_data_loader:torch dataloader object\n",
        "    \"\"\"\n",
        "\n",
        "    transform_train = train_transform\n",
        "    cifar10_training = torchvision.datasets.CIFAR10(root='.', train=True, download=True, transform=transform_train)\n",
        "    cifar10_training_loader = DataLoader(\n",
        "        cifar10_training, shuffle=shuffle, num_workers=num_workers, batch_size=batch_size)\n",
        "\n",
        "    return cifar10_training_loader\n",
        "\n",
        "# define test dataloader\n",
        "def get_testing_dataloader(test_transform, batch_size=128, num_workers=0, shuffle=True):\n",
        "    \"\"\" return training dataloader\n",
        "    Args:\n",
        "        test_transform: transforms for test dataset\n",
        "        path: path to cifar100 test python dataset\n",
        "        batch_size: dataloader batchsize\n",
        "        num_workers: dataloader num_works\n",
        "        shuffle: whether to shuffle \n",
        "    Returns: cifar100_test_loader:torch dataloader object\n",
        "    \"\"\"\n",
        "\n",
        "    transform_test = test_transform\n",
        "    cifar10_test = torchvision.datasets.CIFAR10(root='.', train=False, download=True, transform=transform_test)\n",
        "    cifar10_test_loader = DataLoader(\n",
        "        cifar10_test, shuffle=shuffle, num_workers=num_workers, batch_size=batch_size)\n",
        "\n",
        "    return cifar10_test_loader"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8KyYEqXmSkq_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# implement mish activation function\n",
        "def f_mish(input):\n",
        "    '''\n",
        "    Applies the mish function element-wise:\n",
        "    mish(x) = x * tanh(softplus(x)) = x * tanh(ln(1 + exp(x)))\n",
        "    '''\n",
        "    return input * torch.tanh(F.softplus(input))\n",
        "\n",
        "# implement class wrapper for mish activation function\n",
        "class mish(nn.Module):\n",
        "    '''\n",
        "    Applies the mish function element-wise:\n",
        "    mish(x) = x * tanh(softplus(x)) = x * tanh(ln(1 + exp(x)))\n",
        "\n",
        "    Shape:\n",
        "        - Input: (N, *) where * means, any number of additional\n",
        "          dimensions\n",
        "        - Output: (N, *), same shape as the input\n",
        "\n",
        "    Examples:\n",
        "        >>> m = mish()\n",
        "        >>> input = torch.randn(2)\n",
        "        >>> output = m(input)\n",
        "\n",
        "    '''\n",
        "    def __init__(self):\n",
        "        '''\n",
        "        Init method.\n",
        "        '''\n",
        "        super().__init__()\n",
        "\n",
        "    def forward(self, input):\n",
        "        '''\n",
        "        Forward pass of the function.\n",
        "        '''\n",
        "        return f_mish(input)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WhZDHUX1SkrB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# implement swish activation function\n",
        "def f_swish(input):\n",
        "    '''\n",
        "    Applies the swish function element-wise:\n",
        "    swish(x) = x * sigmoid(x)\n",
        "    '''\n",
        "    return input * torch.sigmoid(input)\n",
        "\n",
        "# implement class wrapper for swish activation function\n",
        "class swish(nn.Module):\n",
        "    '''\n",
        "    Applies the swish function element-wise:\n",
        "    swish(x) = x * sigmoid(x)\n",
        "\n",
        "    Shape:\n",
        "        - Input: (N, *) where * means, any number of additional\n",
        "          dimensions\n",
        "        - Output: (N, *), same shape as the input\n",
        "\n",
        "    Examples:\n",
        "        >>> m = swish()\n",
        "        >>> input = torch.randn(2)\n",
        "        >>> output = m(input)\n",
        "\n",
        "    '''\n",
        "    def __init__(self):\n",
        "        '''\n",
        "        Init method.\n",
        "        '''\n",
        "        super().__init__()\n",
        "\n",
        "    def forward(self, input):\n",
        "        '''\n",
        "        Forward pass of the function.\n",
        "        '''\n",
        "        return f_swish(input)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pcbcz2C-SkrD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class LinearBottleNeck(nn.Module):\n",
        "\n",
        "    def __init__(self, in_channels, out_channels, stride, t=6, class_num=10, activation = 'relu'):\n",
        "        super().__init__()\n",
        "        \n",
        "        if activation == 'relu':\n",
        "            f_activation = nn.ReLU6(inplace=True)\n",
        "            \n",
        "        if activation == 'swish':\n",
        "            f_activation = swish()\n",
        "            \n",
        "        if activation == 'mish':\n",
        "            f_activation = mish()\n",
        "\n",
        "        self.residual = nn.Sequential(\n",
        "            nn.Conv2d(in_channels, in_channels * t, 1),\n",
        "            nn.BatchNorm2d(in_channels * t),\n",
        "            f_activation,\n",
        "\n",
        "            nn.Conv2d(in_channels * t, in_channels * t, 3, stride=stride, padding=1, groups=in_channels * t),\n",
        "            nn.BatchNorm2d(in_channels * t),\n",
        "            f_activation,\n",
        "\n",
        "            nn.Conv2d(in_channels * t, out_channels, 1),\n",
        "            nn.BatchNorm2d(out_channels)\n",
        "        )\n",
        "\n",
        "        self.stride = stride\n",
        "        self.in_channels = in_channels\n",
        "        self.out_channels = out_channels\n",
        "    \n",
        "    def forward(self, x):\n",
        "\n",
        "        residual = self.residual(x)\n",
        "\n",
        "        if self.stride == 1 and self.in_channels == self.out_channels:\n",
        "            residual += x\n",
        "        \n",
        "        return residual\n",
        "\n",
        "class MobileNetV2(nn.Module):\n",
        "\n",
        "    def __init__(self, class_num=10, activation = 'relu'):\n",
        "        super().__init__()\n",
        "        \n",
        "        if activation == 'relu':\n",
        "            f_activation = nn.ReLU6(inplace=True)\n",
        "            \n",
        "        if activation == 'swish':\n",
        "            f_activation = swish()\n",
        "            \n",
        "        if activation == 'mish':\n",
        "            f_activation = mish()\n",
        "\n",
        "        self.pre = nn.Sequential(\n",
        "            nn.Conv2d(3, 32, 1, padding=1),\n",
        "            nn.BatchNorm2d(32),\n",
        "            f_activation\n",
        "        )\n",
        "\n",
        "        self.stage1 = LinearBottleNeck(32, 16, 1, 1, activation = activation)\n",
        "        self.stage2 = self._make_stage(2, 16, 24, 2, 6, activation = activation)\n",
        "        self.stage3 = self._make_stage(3, 24, 32, 2, 6, activation = activation)\n",
        "        self.stage4 = self._make_stage(4, 32, 64, 2, 6, activation = activation)\n",
        "        self.stage5 = self._make_stage(3, 64, 96, 1, 6, activation = activation)\n",
        "        self.stage6 = self._make_stage(3, 96, 160, 1, 6, activation = activation)\n",
        "        self.stage7 = LinearBottleNeck(160, 320, 1, 6, activation = activation)\n",
        "\n",
        "        self.conv1 = nn.Sequential(\n",
        "            nn.Conv2d(320, 1280, 1),\n",
        "            nn.BatchNorm2d(1280),\n",
        "            f_activation\n",
        "        )\n",
        "\n",
        "        self.conv2 = nn.Conv2d(1280, class_num, 1)\n",
        "            \n",
        "    def forward(self, x):\n",
        "        x = self.pre(x)\n",
        "        x = self.stage1(x)\n",
        "        x = self.stage2(x)\n",
        "        x = self.stage3(x)\n",
        "        x = self.stage4(x)\n",
        "        x = self.stage5(x)\n",
        "        x = self.stage6(x)\n",
        "        x = self.stage7(x)\n",
        "        x = self.conv1(x)\n",
        "        x = F.adaptive_avg_pool2d(x, 1)\n",
        "        x = self.conv2(x)\n",
        "        x = x.view(x.size(0), -1)\n",
        "\n",
        "        return x\n",
        "    \n",
        "    def _make_stage(self, repeat, in_channels, out_channels, stride, t, activation = 'relu'):\n",
        "\n",
        "        layers = []\n",
        "        layers.append(LinearBottleNeck(in_channels, out_channels, stride, t, activation = activation))\n",
        "        \n",
        "        while repeat - 1:\n",
        "            layers.append(LinearBottleNeck(out_channels, out_channels, 1, t, activation = activation))\n",
        "            repeat -= 1\n",
        "        \n",
        "        return nn.Sequential(*layers)\n",
        "\n",
        "def mobilenetv2(activation = 'relu'):\n",
        "    return MobileNetV2(activation = activation)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rjrQXGvLSkrE",
        "colab_type": "code",
        "outputId": "cf99cea4-940a-4b05-afed-ae8365d317bb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "source": [
        "trainloader = get_training_dataloader(train_transform)\n",
        "testloader = get_testing_dataloader(test_transform)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\r0it [00:00, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./cifar-10-python.tar.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 99%|█████████▊| 167944192/170498071 [00:12<00:00, 16589326.60it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Extracting ./cifar-10-python.tar.gz to .\n",
            "Files already downloaded and verified\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hRgIq9Z7SkrG",
        "colab_type": "code",
        "outputId": "f8a95071-6e71-4b04-fc32-736fe1ce9011",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "epochs = 100\n",
        "batch_size = 128\n",
        "learning_rate = 0.001\n",
        "device = torch.device('cuda:0' if torch.cuda.is_available() else \"cpu\")\n",
        "device"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda', index=0)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H3rggy47SkrI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = mobilenetv2(activation = 'relu')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "939SUqSCTEXM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DNCr4QuiSkrK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# set loss function\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# set optimizer, only train the classifier parameters, feature parameters are frozen\n",
        "optimizer = Adam(model.parameters(), lr=learning_rate)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eZwBaUOSSkrM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_stats = pd.DataFrame(columns = ['Epoch', 'Time per epoch', 'Avg time per step', 'Train loss', 'Train accuracy', 'Train top-3 accuracy','Test loss', 'Test accuracy', 'Test top-3 accuracy']) "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6PvO218wSkrN",
        "colab_type": "code",
        "outputId": "f171f959-b6c0-45c1-90c7-830a34804749",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 127
        }
      },
      "source": [
        "#train the model\n",
        "model.to(device)\n",
        "\n",
        "steps = 0\n",
        "running_loss = 0\n",
        "for epoch in range(epochs):\n",
        "    \n",
        "    since = time.time()\n",
        "    \n",
        "    train_accuracy = 0\n",
        "    top3_train_accuracy = 0 \n",
        "    for inputs, labels in trainloader:\n",
        "        steps += 1\n",
        "        # Move input and label tensors to the default device\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "        \n",
        "        optimizer.zero_grad()\n",
        "        \n",
        "        logps = model.forward(inputs)\n",
        "        loss = criterion(logps, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "        \n",
        "        # calculate train top-1 accuracy\n",
        "        ps = torch.exp(logps)\n",
        "        top_p, top_class = ps.topk(1, dim=1)\n",
        "        equals = top_class == labels.view(*top_class.shape)\n",
        "        train_accuracy += torch.mean(equals.type(torch.FloatTensor)).item()\n",
        "        \n",
        "        # Calculate train top-3 accuracy\n",
        "        np_top3_class = ps.topk(3, dim=1)[1].cpu().numpy()\n",
        "        target_numpy = labels.cpu().numpy()\n",
        "        top3_train_accuracy += np.mean([1 if target_numpy[i] in np_top3_class[i] else 0 for i in range(0, len(target_numpy))])\n",
        "        \n",
        "    time_elapsed = time.time() - since\n",
        "    \n",
        "    test_loss = 0\n",
        "    test_accuracy = 0\n",
        "    top3_test_accuracy = 0\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in testloader:\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "            logps = model.forward(inputs)\n",
        "            batch_loss = criterion(logps, labels)\n",
        "\n",
        "            test_loss += batch_loss.item()\n",
        "\n",
        "            # Calculate test top-1 accuracy\n",
        "            ps = torch.exp(logps)\n",
        "            top_p, top_class = ps.topk(1, dim=1)\n",
        "            equals = top_class == labels.view(*top_class.shape)\n",
        "            test_accuracy += torch.mean(equals.type(torch.FloatTensor)).item()\n",
        "            \n",
        "            # Calculate test top-3 accuracy\n",
        "            np_top3_class = ps.topk(3, dim=1)[1].cpu().numpy()\n",
        "            target_numpy = labels.cpu().numpy()\n",
        "            top3_test_accuracy += np.mean([1 if target_numpy[i] in np_top3_class[i] else 0 for i in range(0, len(target_numpy))])\n",
        "\n",
        "    print(f\"Epoch {epoch+1}/{epochs}.. \"\n",
        "          f\"Time per epoch: {time_elapsed:.4f}.. \"\n",
        "          f\"Average time per step: {time_elapsed/len(trainloader):.4f}.. \"\n",
        "          f\"Train loss: {running_loss/len(trainloader):.4f}.. \"\n",
        "          f\"Train accuracy: {train_accuracy/len(trainloader):.4f}.. \"\n",
        "          f\"Top-3 train accuracy: {top3_train_accuracy/len(trainloader):.4f}.. \"\n",
        "          f\"Test loss: {test_loss/len(testloader):.4f}.. \"\n",
        "          f\"Test accuracy: {test_accuracy/len(testloader):.4f}.. \"\n",
        "          f\"Top-3 test accuracy: {top3_test_accuracy/len(testloader):.4f}\")\n",
        "\n",
        "    train_stats = train_stats.append({'Epoch': epoch, 'Time per epoch':time_elapsed, 'Avg time per step': time_elapsed/len(trainloader), 'Train loss' : running_loss/len(trainloader), 'Train accuracy': train_accuracy/len(trainloader), 'Train top-3 accuracy':top3_train_accuracy/len(trainloader),'Test loss' : test_loss/len(testloader), 'Test accuracy': test_accuracy/len(testloader), 'Test top-3 accuracy':top3_test_accuracy/len(testloader)}, ignore_index=True)\n",
        "\n",
        "    running_loss = 0\n",
        "    model.train()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\r170500096it [00:30, 16589326.60it/s]                               "
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100.. Time per epoch: 43.6952.. Average time per step: 0.1118.. Train loss: 1.6586.. Train accuracy: 0.3780.. Top-3 train accuracy: 0.7227.. Test loss: 1.4369.. Test accuracy: 0.4674.. Top-3 test accuracy: 0.8081\n",
            "Epoch 2/100.. Time per epoch: 43.5468.. Average time per step: 0.1114.. Train loss: 1.3392.. Train accuracy: 0.5111.. Top-3 train accuracy: 0.8290.. Test loss: 1.2000.. Test accuracy: 0.5670.. Top-3 test accuracy: 0.8606\n",
            "Epoch 3/100.. Time per epoch: 43.5816.. Average time per step: 0.1115.. Train loss: 1.1856.. Train accuracy: 0.5705.. Top-3 train accuracy: 0.8648.. Test loss: 1.0755.. Test accuracy: 0.6155.. Top-3 test accuracy: 0.8837\n",
            "Epoch 4/100.. Time per epoch: 43.5662.. Average time per step: 0.1114.. Train loss: 1.0705.. Train accuracy: 0.6175.. Top-3 train accuracy: 0.8863.. Test loss: 1.0241.. Test accuracy: 0.6415.. Top-3 test accuracy: 0.8974\n",
            "Epoch 5/100.. Time per epoch: 43.6217.. Average time per step: 0.1116.. Train loss: 0.9826.. Train accuracy: 0.6494.. Top-3 train accuracy: 0.9014.. Test loss: 0.8905.. Test accuracy: 0.6856.. Top-3 test accuracy: 0.9222\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4lI4nozsSkrP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_stats.to_csv('train_log_MobileNetv2_Relu.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}